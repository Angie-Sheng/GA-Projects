{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create rolling-windows and come up with features with min, max, mean and std "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "train_df_new = pd.read_csv('train_df.csv',index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>mean_item_price</th>\n",
       "      <th>item_cnt</th>\n",
       "      <th>mean_item_cnt</th>\n",
       "      <th>transactions</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>item_cnt_month</th>\n",
       "      <th>item_price_unit</th>\n",
       "      <th>hist_min_item_price</th>\n",
       "      <th>hist_max_item_price</th>\n",
       "      <th>price_increase</th>\n",
       "      <th>price_decrease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5572</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10730.00</td>\n",
       "      <td>1532.8572</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18979.5</td>\n",
       "      <td>10730.00</td>\n",
       "      <td>8249.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5643</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4775.21</td>\n",
       "      <td>2387.6050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35260.0</td>\n",
       "      <td>4775.21</td>\n",
       "      <td>30484.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5583</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1188.30</td>\n",
       "      <td>594.1500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5592.0</td>\n",
       "      <td>1188.30</td>\n",
       "      <td>4403.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7893</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5970.00</td>\n",
       "      <td>1990.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27950.0</td>\n",
       "      <td>5970.00</td>\n",
       "      <td>21980.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7894</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1490.00</td>\n",
       "      <td>1490.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1490.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25880.0</td>\n",
       "      <td>1490.00</td>\n",
       "      <td>24390.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6728113</th>\n",
       "      <td>33</td>\n",
       "      <td>36</td>\n",
       "      <td>9103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6728114</th>\n",
       "      <td>33</td>\n",
       "      <td>36</td>\n",
       "      <td>9107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>300.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6728115</th>\n",
       "      <td>33</td>\n",
       "      <td>36</td>\n",
       "      <td>5704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1750.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6728116</th>\n",
       "      <td>33</td>\n",
       "      <td>36</td>\n",
       "      <td>12733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2980.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2980.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6728117</th>\n",
       "      <td>33</td>\n",
       "      <td>36</td>\n",
       "      <td>15925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11899.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11899.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date_block_num  shop_id  item_id  item_category_id  item_price  \\\n",
       "0                     0        2     5572               2.0    10730.00   \n",
       "1                     0        2     5643               2.0     4775.21   \n",
       "2                     0        2     5583               5.0     1188.30   \n",
       "3                     0        2     7893               6.0     5970.00   \n",
       "4                     0        2     7894               6.0     1490.00   \n",
       "6728113              33       36     9103               0.0        0.00   \n",
       "6728114              33       36     9107               0.0        0.00   \n",
       "6728115              33       36     5704               0.0        0.00   \n",
       "6728116              33       36    12733               0.0        0.00   \n",
       "6728117              33       36    15925               0.0        0.00   \n",
       "\n",
       "         mean_item_price  item_cnt  mean_item_cnt  transactions  year  month  \\\n",
       "0              1532.8572       9.0       1.285714           7.0  2013      0   \n",
       "1              2387.6050       0.0       0.000000           2.0  2013      0   \n",
       "2               594.1500       2.0       1.000000           2.0  2013      0   \n",
       "3              1990.0000       3.0       1.000000           3.0  2013      0   \n",
       "4              1490.0000       1.0       1.000000           1.0  2013      0   \n",
       "6728113           0.0000       0.0       0.000000           0.0  2015      9   \n",
       "6728114           0.0000       0.0       0.000000           0.0  2015      9   \n",
       "6728115           0.0000       0.0       0.000000           0.0  2015      9   \n",
       "6728116           0.0000       0.0       0.000000           0.0  2015      9   \n",
       "6728117           0.0000       0.0       0.000000           0.0  2015      9   \n",
       "\n",
       "         item_cnt_month  item_price_unit  hist_min_item_price  \\\n",
       "0                   1.0           1192.0                  0.0   \n",
       "1                   0.0              inf                  0.0   \n",
       "2                   1.0            594.0                  0.0   \n",
       "3                   2.0           1990.0                  0.0   \n",
       "4                   2.0           1490.0                  0.0   \n",
       "6728113             NaN              0.0                  0.0   \n",
       "6728114             NaN              0.0                  0.0   \n",
       "6728115             NaN              0.0                  0.0   \n",
       "6728116             NaN              0.0                  0.0   \n",
       "6728117             NaN              0.0                  0.0   \n",
       "\n",
       "         hist_max_item_price  price_increase  price_decrease  \n",
       "0                    18979.5        10730.00         8249.50  \n",
       "1                    35260.0         4775.21        30484.79  \n",
       "2                     5592.0         1188.30         4403.70  \n",
       "3                    27950.0         5970.00        21980.00  \n",
       "4                    25880.0         1490.00        24390.00  \n",
       "6728113                500.0            0.00          500.00  \n",
       "6728114                300.0            0.00          300.00  \n",
       "6728115               1750.0            0.00         1750.00  \n",
       "6728116               2980.0            0.00         2980.00  \n",
       "6728117              11899.0            0.00        11899.00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_new.head().append(train_df_new.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create rolling-windows and come up with features with min, max, mean and std "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min value\n",
    "f_min = lambda x: x.rolling(window=3, min_periods=1).min()\n",
    "# Max value\n",
    "f_max = lambda x: x.rolling(window=3, min_periods=1).max()\n",
    "# Mean value\n",
    "f_mean = lambda x: x.rolling(window=3, min_periods=1).mean()\n",
    "# Standard deviation\n",
    "f_std = lambda x: x.rolling(window=3, min_periods=1).std()\n",
    " \n",
    "function_list = [f_min, f_max, f_mean, f_std]\n",
    "function_name = ['min', 'max', 'mean', 'std']\n",
    " \n",
    "for i in range(len(function_list)):\n",
    "    train_df_new[('item_cnt_%s' % function_name[i])] = train_df_new.sort_values('date_block_num').groupby(['shop_id', 'item_category_id', 'item_id'])['item_cnt'].apply(function_list[i])\n",
    "\n",
    "#print(train_df_new)\n",
    "\n",
    "# Fill the empty std features with 0\n",
    "train_df_new['item_cnt_std'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_list = [1, 2, 3]\n",
    " \n",
    "for lag in lag_list:\n",
    "    ft_name = ('item_cnt_shifted%s' % lag)\n",
    "    train_df_new[ft_name] = train_df_new.sort_values('date_block_num').groupby(['shop_id', 'item_category_id', 'item_id'])['item_cnt'].shift(lag)\n",
    "    # Fill the empty shifted features with 0\n",
    "    train_df_new[ft_name].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create shifted features(lagging) for 3 previous consecutive months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_list = [1, 2, 3]\n",
    " \n",
    "for lag in lag_list:\n",
    "    ft_name = ('item_cnt_shifted%s' % lag)\n",
    "    train_df_new[ft_name] = train_df_new.sort_values('date_block_num').groupby(['shop_id', 'item_category_id', 'item_id'])['item_cnt'].shift(lag)\n",
    "    # Fill the empty shifted features with 0\n",
    "    train_df_new[ft_name].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a feature for item sales trend, which could be calculated by substracting the lagging sales from current sales and take the average to represent the change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_new['item_trend'] = train_df_new['item_cnt']\n",
    " \n",
    "for lag in lag_list:\n",
    "    ft_name = ('item_cnt_shifted%s' % lag)\n",
    "    train_df_new['item_trend'] -= train_df_new[ft_name]\n",
    " \n",
    "train_df_new['item_trend'] /= len(lag_list) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get rid of the first three months' data because the lagging features we just created would be null. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_df_new.query('date_block_num >= 3 and date_block_num < 28').copy()\n",
    "validation_set = train_df_new.query('date_block_num >= 28 and date_block_num < 33').copy()\n",
    "test_set = train_df_new.query('date_block_num == 33').copy()\n",
    " \n",
    "train_set.dropna(subset=['item_cnt_month'], inplace=True)\n",
    "validation_set.dropna(subset=['item_cnt_month'], inplace=True)\n",
    " \n",
    "train_set.dropna(inplace=True)\n",
    "validation_set.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shop mean encoding.\n",
    "gp_shop_mean = train_set.groupby(['shop_id']).agg({'item_cnt_month': ['mean']})\n",
    "gp_shop_mean.columns = ['shop_mean']\n",
    "gp_shop_mean.reset_index(inplace=True)\n",
    "# Item mean encoding.\n",
    "gp_item_mean = train_set.groupby(['item_id']).agg({'item_cnt_month': ['mean']})\n",
    "gp_item_mean.columns = ['item_mean']\n",
    "gp_item_mean.reset_index(inplace=True)\n",
    "# Shop with item mean encoding.\n",
    "gp_shop_item_mean = train_set.groupby(['shop_id', 'item_id']).agg({'item_cnt_month': ['mean']})\n",
    "gp_shop_item_mean.columns = ['shop_item_mean']\n",
    "gp_shop_item_mean.reset_index(inplace=True)\n",
    "# Year mean encoding.\n",
    "gp_year_mean = train_set.groupby(['year']).agg({'item_cnt_month': ['mean']})\n",
    "gp_year_mean.columns = ['year_mean']\n",
    "gp_year_mean.reset_index(inplace=True)\n",
    "# Month mean encoding.\n",
    "gp_month_mean = train_set.groupby(['month']).agg({'item_cnt_month': ['mean']})\n",
    "gp_month_mean.columns = ['month_mean']\n",
    "gp_month_mean.reset_index(inplace=True)\n",
    " \n",
    " \n",
    "# Add meand encoding features to train set.\n",
    "train_set = pd.merge(train_set, gp_shop_mean, on=['shop_id'], how='left')\n",
    "train_set = pd.merge(train_set, gp_item_mean, on=['item_id'], how='left')\n",
    "train_set = pd.merge(train_set, gp_shop_item_mean, on=['shop_id', 'item_id'], how='left')\n",
    "train_set = pd.merge(train_set, gp_year_mean, on=['year'], how='left')\n",
    "train_set = pd.merge(train_set, gp_month_mean, on=['month'], how='left')\n",
    "# Add meand encoding features to validation set.\n",
    "validation_set = pd.merge(validation_set, gp_shop_mean, on=['shop_id'], how='left')\n",
    "validation_set = pd.merge(validation_set, gp_item_mean, on=['item_id'], how='left')\n",
    "validation_set = pd.merge(validation_set, gp_shop_item_mean, on=['shop_id', 'item_id'], how='left')\n",
    "validation_set = pd.merge(validation_set, gp_year_mean, on=['year'], how='left')\n",
    "validation_set = pd.merge(validation_set, gp_month_mean, on=['month'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and validation sets and labels. \n",
    "X_train = train_set.drop(['item_cnt_month', 'date_block_num'], axis=1)\n",
    "Y_train = train_set['item_cnt_month'].astype(int)\n",
    "X_validation = validation_set.drop(['item_cnt_month', 'date_block_num'], axis=1)\n",
    "Y_validation = validation_set['item_cnt_month'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integer features (used by catboost model).\n",
    "int_features = ['shop_id', 'item_id', 'year', 'month']\n",
    " \n",
    "X_train[int_features] = X_train[int_features].astype('int32')\n",
    "X_validation[int_features] = X_validation[int_features].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv', dtype={'ID': 'int32', 'shop_id': 'int32', \n",
    "                                                  'item_id': 'int32'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill in the features for test data(it only contains shop_id & item_id before, but we would predict on more features). The feature value filled in are the last record from train data corresponding to the item_id and shop_id \n",
    "\n",
    "latest_records = pd.concat([train_set, validation_set]).drop_duplicates(subset=['shop_id', 'item_id'], keep='last')\n",
    "\n",
    "X_test = pd.merge(test, latest_records, on=['shop_id', 'item_id'], how='left', suffixes=['', '_'])  \n",
    "X_test.head().append(X_test.tail())\n",
    "X_test['year'] = 2015\n",
    "X_test['month'] = 9\n",
    "X_test.drop('item_cnt_month', axis=1, inplace=True)\n",
    "X_test[int_features] = X_test[int_features].astype('int32')\n",
    "X_test = X_test[X_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill null values with median\n",
    "sets = [X_train, X_validation, X_test]\n",
    " \n",
    "            \n",
    "for dataset in sets:\n",
    "    for shop_id in dataset['shop_id'].unique():\n",
    "        for column in dataset.columns:\n",
    "            shop_median = dataset[(dataset['shop_id'] == shop_id)][column].median()\n",
    "            dataset.loc[(dataset[column].isnull()) & (dataset['shop_id'] == shop_id), column] = shop_median\n",
    "            \n",
    "# Fill remaining missing values on test set with mean.\n",
    "X_test.fillna(X_test.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(['item_category_id'], axis=1, inplace=True)\n",
    "X_validation.drop(['item_category_id'], axis=1, inplace=True)\n",
    "X_test.drop(['item_category_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   shop_id  item_id  item_price  mean_item_price  item_cnt  mean_item_cnt  \\\n",
      "0      2.0   5572.0      2980.0           1490.0       2.0            1.0   \n",
      "1      2.0   5643.0         0.0              0.0       0.0            0.0   \n",
      "2      2.0   5583.0         0.0              0.0       0.0            0.0   \n",
      "3      2.0   7893.0      9350.0           1870.0       5.0            1.0   \n",
      "4      2.0   7894.0         0.0              0.0       0.0            0.0   \n",
      "\n",
      "   transactions    year  month  item_price_unit  ...  item_cnt_std  \\\n",
      "0           2.0  2013.0    3.0           1490.0  ...      0.577350   \n",
      "1           0.0  2013.0    3.0              0.0  ...      0.000000   \n",
      "2           0.0  2013.0    3.0              0.0  ...      0.000000   \n",
      "3           5.0  2013.0    3.0           1870.0  ...      2.081666   \n",
      "4           0.0  2013.0    3.0              0.0  ...      0.000000   \n",
      "\n",
      "   item_cnt_shifted1  item_cnt_shifted2  item_cnt_shifted3  item_trend  \\\n",
      "0                1.0                1.0                9.0       -2.25   \n",
      "1                0.0                0.0                0.0        0.00   \n",
      "2                0.0                0.0                0.0        0.00   \n",
      "3                1.0                2.0                3.0       -0.25   \n",
      "4                0.0                0.0                0.0        0.00   \n",
      "\n",
      "   shop_mean  item_mean  shop_item_mean  year_mean  month_mean  \n",
      "0   0.097844   1.004766            0.84   0.135041    0.157318  \n",
      "1   0.097844   1.818702            1.84   0.135041    0.157318  \n",
      "2   0.097844   0.589524            0.04   0.135041    0.157318  \n",
      "3   0.097844   3.038388            3.12   0.135041    0.157318  \n",
      "4   0.097844   3.670837            1.68   0.135041    0.157318  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   shop_id  item_id  item_price  mean_item_price  item_cnt  mean_item_cnt  \\\n",
      "0      2.0   5572.0      1590.0          1590.00       1.0            1.0   \n",
      "1      2.0   5643.0         0.0             0.00       0.0            0.0   \n",
      "2      2.0   5583.0         0.0             0.00       0.0            0.0   \n",
      "3      2.0   7893.0         0.0             0.00       0.0            0.0   \n",
      "4      2.0   7894.0      4579.5          2289.75       2.0            1.0   \n",
      "\n",
      "   transactions    year  month  item_price_unit  ...  item_cnt_std  \\\n",
      "0           1.0  2015.0    4.0           1590.0  ...      0.000000   \n",
      "1           0.0  2015.0    4.0              0.0  ...      0.000000   \n",
      "2           0.0  2015.0    4.0              0.0  ...      0.000000   \n",
      "3           0.0  2015.0    4.0              0.0  ...      0.000000   \n",
      "4           2.0  2015.0    4.0           2289.0  ...      2.081666   \n",
      "\n",
      "   item_cnt_shifted1  item_cnt_shifted2  item_cnt_shifted3  item_trend  \\\n",
      "0                1.0                1.0                1.0        -0.5   \n",
      "1                0.0                0.0                0.0         0.0   \n",
      "2                0.0                0.0                0.0         0.0   \n",
      "3                0.0                0.0                0.0         0.0   \n",
      "4                1.0                5.0                2.0        -1.5   \n",
      "\n",
      "   shop_mean  item_mean  shop_item_mean  year_mean  month_mean  \n",
      "0   0.097844   1.004766            0.84    0.22495    0.140806  \n",
      "1   0.097844   1.818702            1.84    0.22495    0.140806  \n",
      "2   0.097844   0.589524            0.04    0.22495    0.140806  \n",
      "3   0.097844   3.038388            3.12    0.22495    0.140806  \n",
      "4   0.097844   3.670837            1.68    0.22495    0.140806  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_validation.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:43:05] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:43:05] WARNING: src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n",
      "[0]\tvalidation_0-rmse:0.942838\tvalidation_1-rmse:0.92285\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 20 rounds.\n",
      "[20]\tvalidation_0-rmse:0.684562\tvalidation_1-rmse:0.790805\n",
      "Stopping. Best iteration:\n",
      "[18]\tvalidation_0-rmse:0.687705\tvalidation_1-rmse:0.788256\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.7, eta=0.3, gamma=0,\n",
       "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
       "             max_depth=8, min_child_weight=1000, missing=None, n_estimators=500,\n",
       "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=0, silent=None,\n",
       "             subsample=0.7, verbosity=1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use only part of features on XGBoost.\n",
    "xgb_features = ['item_cnt','item_cnt_mean', 'item_cnt_std', 'item_cnt_shifted1', \n",
    "                'item_cnt_shifted2', 'item_cnt_shifted3', 'shop_mean', \n",
    "                'shop_item_mean', 'item_trend', 'mean_item_cnt']\n",
    "xgb_train = X_train[xgb_features]\n",
    "xgb_val = X_validation[xgb_features]\n",
    "xgb_test = X_test[xgb_features]\n",
    " \n",
    "xgb_model = XGBRegressor(max_depth=8, \n",
    "                         n_estimators=500, \n",
    "                         min_child_weight=1000,  \n",
    "                         colsample_bytree=0.7, \n",
    "                         subsample=0.7, \n",
    "                         eta=0.3, \n",
    "                         seed=0)\n",
    "xgb_model.fit(xgb_train, \n",
    "              Y_train, \n",
    "              eval_metric=\"rmse\", \n",
    "              eval_set=[(xgb_train, Y_train), (xgb_val, Y_validation)], \n",
    "              verbose=20, \n",
    "              early_stopping_rounds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rmse: 0.692250599852641\n",
      "Validation rmse: 0.7897789171758853\n"
     ]
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (15, 6)\n",
    "plot_importance(xgb_model)\n",
    "plt.show()\n",
    "xgb_train_pred = xgb_model.predict(xgb_train)\n",
    "xgb_val_pred = xgb_model.predict(xgb_val)\n",
    "xgb_test_pred = xgb_model.predict(xgb_test)\n",
    "print('Train rmse:', np.sqrt(mean_squared_error(Y_train, xgb_train_pred)))\n",
    "print('Validation rmse:', np.sqrt(mean_squared_error(Y_validation, xgb_val_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=50, n_jobs=-1, oob_score=False,\n",
       "                      random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use only part of features on random forest.\n",
    "rf_features = ['shop_id', 'item_id', 'item_cnt', 'transactions', 'year',\n",
    "               'item_cnt_mean', 'item_cnt_std', 'item_cnt_shifted1', \n",
    "               'shop_mean', 'item_mean', 'item_trend', 'mean_item_cnt']\n",
    "rf_train = X_train[rf_features]\n",
    "rf_val = X_validation[rf_features]\n",
    "rf_test = X_test[rf_features]\n",
    " \n",
    "rf_model = RandomForestRegressor(n_estimators=50, max_depth=7, random_state=0, n_jobs=-1)\n",
    "rf_model.fit(rf_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rmse: 0.6986130498585467\n",
      "Validation rmse: 0.7761624203123252\n"
     ]
    }
   ],
   "source": [
    "rf_train_pred = rf_model.predict(rf_train)\n",
    "rf_val_pred = rf_model.predict(rf_val)\n",
    "rf_test_pred = rf_model.predict(rf_test)\n",
    " \n",
    "print('Train rmse:', np.sqrt(mean_squared_error(Y_train, rf_train_pred)))\n",
    "print('Validation rmse:', np.sqrt(mean_squared_error(Y_validation, rf_val_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_features = ['item_cnt', 'item_cnt_shifted1', 'item_trend', 'mean_item_cnt', 'shop_mean']\n",
    "lr_train = X_train[lr_features]\n",
    "lr_val = X_validation[lr_features]\n",
    "lr_test = X_test[lr_features]\n",
    " \n",
    "lr_scaler = MinMaxScaler()\n",
    "lr_scaler.fit(lr_train)\n",
    "lr_train = lr_scaler.transform(lr_train)\n",
    "lr_val = lr_scaler.transform(lr_val)\n",
    "lr_test = lr_scaler.transform(lr_test)\n",
    " \n",
    "lr_model = LinearRegression(n_jobs=-1)\n",
    "lr_model.fit(lr_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rmse: 0.7347110565392222\n",
      "Validation rmse: 0.7755309685532078\n"
     ]
    }
   ],
   "source": [
    "lr_train_pred = lr_model.predict(lr_train)\n",
    "lr_val_pred = lr_model.predict(lr_val)\n",
    "lr_test_pred = lr_model.predict(lr_test)\n",
    "print('Train rmse:', np.sqrt(mean_squared_error(Y_train, lr_train_pred)))\n",
    "print('Validation rmse:', np.sqrt(mean_squared_error(Y_validation, lr_val_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=13, metric='minkowski',\n",
       "                    metric_params=None, n_jobs=-1, n_neighbors=9, p=2,\n",
       "                    weights='uniform')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_features = ['item_cnt', 'item_cnt_mean', 'item_cnt_std', 'item_cnt_shifted1',\n",
    "                'item_cnt_shifted2', 'shop_mean', 'shop_item_mean', \n",
    "                'item_trend', 'mean_item_cnt']\n",
    " \n",
    "# Subsample train set (using the whole data was taking too long).\n",
    "X_train_sampled = X_train[:100000]\n",
    "Y_train_sampled = Y_train[:100000]\n",
    " \n",
    "knn_train = X_train_sampled[knn_features]\n",
    "knn_val = X_validation[knn_features]\n",
    "knn_test = X_test[knn_features]\n",
    " \n",
    "knn_scaler = MinMaxScaler()\n",
    "knn_scaler.fit(knn_train)\n",
    "knn_train = knn_scaler.transform(knn_train)\n",
    "knn_val = knn_scaler.transform(knn_val)\n",
    "knn_test = knn_scaler.transform(knn_test)\n",
    " \n",
    "knn_model = KNeighborsRegressor(n_neighbors=9, leaf_size=13, n_jobs=-1)\n",
    "knn_model.fit(knn_train, Y_train_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rmse: 0.48654615453605954\n",
      "Validation rmse: 0.8003598014372081\n"
     ]
    }
   ],
   "source": [
    "knn_train_pred = knn_model.predict(knn_train)\n",
    "knn_val_pred = knn_model.predict(knn_val)\n",
    "knn_test_pred = knn_model.predict(knn_test)\n",
    "print('Train rmse:', np.sqrt(mean_squared_error(Y_train_sampled, knn_train_pred)))\n",
    "print('Validation rmse:', np.sqrt(mean_squared_error(Y_validation, knn_val_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset that will be the train set of the ensemble model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xgbm</th>\n",
       "      <th>random_forest</th>\n",
       "      <th>linear_regression</th>\n",
       "      <th>knn</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.688442</td>\n",
       "      <td>0.621809</td>\n",
       "      <td>0.598764</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.638456</td>\n",
       "      <td>0.557902</td>\n",
       "      <td>0.044736</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.103210</td>\n",
       "      <td>0.207674</td>\n",
       "      <td>0.044736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.814267</td>\n",
       "      <td>0.947778</td>\n",
       "      <td>0.044736</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.588363</td>\n",
       "      <td>1.566086</td>\n",
       "      <td>1.455702</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.638456</td>\n",
       "      <td>0.457695</td>\n",
       "      <td>0.044736</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.439195</td>\n",
       "      <td>0.207674</td>\n",
       "      <td>0.044736</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.103210</td>\n",
       "      <td>0.059621</td>\n",
       "      <td>0.044736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.368585</td>\n",
       "      <td>0.207674</td>\n",
       "      <td>0.044736</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.732229</td>\n",
       "      <td>1.125031</td>\n",
       "      <td>1.151157</td>\n",
       "      <td>2.888889</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.528217</td>\n",
       "      <td>0.273054</td>\n",
       "      <td>0.044736</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.439195</td>\n",
       "      <td>0.408428</td>\n",
       "      <td>0.044736</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.638456</td>\n",
       "      <td>0.670721</td>\n",
       "      <td>0.044736</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.528217</td>\n",
       "      <td>0.457695</td>\n",
       "      <td>0.044736</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.125656</td>\n",
       "      <td>0.056047</td>\n",
       "      <td>0.044736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.461753</td>\n",
       "      <td>0.284075</td>\n",
       "      <td>0.044736</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.276648</td>\n",
       "      <td>0.203541</td>\n",
       "      <td>0.044736</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.528217</td>\n",
       "      <td>0.284075</td>\n",
       "      <td>0.044736</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.569868</td>\n",
       "      <td>0.566782</td>\n",
       "      <td>0.598764</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.530698</td>\n",
       "      <td>0.597711</td>\n",
       "      <td>1.075021</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        xgbm  random_forest  linear_regression       knn  label\n",
       "0   0.688442       0.621809           0.598764  1.000000      0\n",
       "1   0.638456       0.557902           0.044736  0.777778      0\n",
       "2   0.103210       0.207674           0.044736  0.000000      0\n",
       "3   0.814267       0.947778           0.044736  0.111111      4\n",
       "4   1.588363       1.566086           1.455702  0.666667      1\n",
       "5   0.638456       0.457695           0.044736  0.111111      1\n",
       "6   0.439195       0.207674           0.044736  0.111111      0\n",
       "7   0.103210       0.059621           0.044736  0.000000      1\n",
       "8   0.368585       0.207674           0.044736  0.111111      0\n",
       "9   1.732229       1.125031           1.151157  2.888889      2\n",
       "10  0.528217       0.273054           0.044736  0.555556      0\n",
       "11  0.439195       0.408428           0.044736  0.111111      0\n",
       "12  0.638456       0.670721           0.044736  0.111111      0\n",
       "13  0.528217       0.457695           0.044736  0.333333      0\n",
       "14  0.125656       0.056047           0.044736  0.000000      0\n",
       "15  0.461753       0.284075           0.044736  0.222222      1\n",
       "16  0.276648       0.203541           0.044736  0.111111      0\n",
       "17  0.528217       0.284075           0.044736  0.111111      0\n",
       "18  0.569868       0.566782           0.598764  0.888889      0\n",
       "19  0.530698       0.597711           1.075021  0.333333      0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_level = pd.DataFrame(xgb_val_pred, columns=['xgbm'])\n",
    "first_level['random_forest'] = rf_val_pred\n",
    "first_level['linear_regression'] = lr_val_pred\n",
    "first_level['knn'] = knn_val_pred\n",
    "first_level['label'] = Y_validation.values\n",
    "first_level.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset that will be the test set of the ensemble model.\n",
    "first_level_test = pd.DataFrame(xgb_test_pred, columns=['xgbm'])\n",
    "first_level_test['random_forest'] = rf_test_pred\n",
    "first_level_test['linear_regression'] = lr_test_pred\n",
    "first_level_test['knn'] = knn_test_pred\n",
    "first_level_test.head()\n",
    "# Create a meta_model and vote\n",
    "meta_model = LinearRegression(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop label from dataset.\n",
    "first_level.drop('label', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_model.fit(first_level, Y_validation)\n",
    "ensemble_pred = meta_model.predict(first_level)\n",
    "final_predictions = meta_model.predict(first_level_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rmse: 0.7649992807983159\n"
     ]
    }
   ],
   "source": [
    "print('Train rmse:', np.sqrt(mean_squared_error(ensemble_pred, Y_validation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>item_cnt_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  item_cnt_month\n",
       "0   0            0.82\n",
       "1   1            0.08\n",
       "2   2            1.27\n",
       "3   3            0.06\n",
       "4   4            0.08\n",
       "5   5            0.94\n",
       "6   6            1.24\n",
       "7   7            0.21\n",
       "8   8            1.98\n",
       "9   9            0.06"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df = pd.DataFrame(test['ID'], columns=['ID'])\n",
    "prediction_df['item_cnt_month'] = final_predictions.clip(0., 20.)\n",
    "prediction_df['item_cnt_month']= prediction_df['item_cnt_month'].round(2)\n",
    "prediction_df.to_csv('submission.csv', index=False)\n",
    "prediction_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
